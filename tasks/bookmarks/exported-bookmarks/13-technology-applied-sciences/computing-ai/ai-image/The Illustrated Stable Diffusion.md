# The Illustrated Stable Diffusion

**URL:** https://www.google.com/url?q=https://jalammar.github.io/illustrated-stable-diffusion/&usg=AOvVaw0H5hjXHfv-GJKufGKEPvOk

**Created:** 2023-09-14T05:35:15.522Z

**Tags:** 

**Favorite:** false

## Excerpt

Translations: Chinese, Vietnamese.   (V2 Nov 2022: Updated images for more precise description of forward diffusion. A few more images in this version)  AI image generation is the most recent AI capability blowing people’s minds (mine included). The ability to create striking visuals from text descriptions has a magical quality to it and points clearly to a shift in how humans create art. The release of Stable Diffusion is a clear milestone in this development because it made a high-performance model available to the masses (performance in terms of image quality, as well as speed and relatively low resource/memory requirements).    After experimenting with AI image generation, you may start to wonder how it works.  This is a gentle introduction to how Stable Diffusion works.            Stable Diffusion is versatile in that it can be used in a number of different ways. Let’s focus at first on image generation from text only (text2img). The image above shows an example text input and the resulting generated image (The actual complete prompt is here). Aside from text to image, another main way of using it is by making it alter images (so inputs are text + image).

