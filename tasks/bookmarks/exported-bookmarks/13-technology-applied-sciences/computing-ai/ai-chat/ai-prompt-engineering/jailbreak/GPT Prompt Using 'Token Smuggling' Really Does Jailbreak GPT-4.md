# GPT Prompt Using 'Token Smuggling' Really Does Jailbreak GPT-4

**URL:** https://www.google.com/url?q=https://www.piratewires.com/p/gpt4-token-smuggling&usg=AOvVaw088-5XjG4myXTtfuMVHrgu

**Created:** 2023-07-21T02:45:59.213Z

**Tags:** 

**Favorite:** false

## Excerpt

the prompt bypasses content filters by asking gpt to predict what a llm's next token would be, splitting up 'bad' words

## Cover Image

![Cover](https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe6e94132-165b-4704-bf79-0e06a8c128ad_1592x920.png)

