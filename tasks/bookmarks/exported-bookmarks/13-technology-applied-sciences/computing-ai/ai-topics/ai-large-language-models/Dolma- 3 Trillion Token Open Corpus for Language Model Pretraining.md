# Dolma: 3 Trillion Token Open Corpus for Language Model Pretraining

**URL:** https://medium.com/ai2-blog/dolma-3-trillion-tokens-open-llm-corpus-9a0ff4b8da64?source=list-d4e1c0c2e4ff--------9-------predefined%3Ad4e1c0c2e4ff%3AREADING_LIST---------------------

**Created:** 2023-09-29T04:39:38.606Z

**Tags:** 

**Favorite:** false

## Excerpt

We released Dolma, OLMoâ€™s pretraining dataset. Dolma open dataset of 3 trillion tokens. Available on  HuggingFace under the ImpACT license

## Cover Image

![Cover](https://miro.medium.com/v2/resize:fill:1200:632/g:fp:0.55:0.51/0*YKtUvoxFpV3pzPwC)

